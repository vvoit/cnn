{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total traing NORMAL images: 1200\n",
      "total traing PNEUMONIA images: 1200\n",
      "\n",
      "total validation NORMAL images: 300\n",
      "total validation PNEUMONIA images: 300\n",
      "\n",
      "total test NORMAL images: 83\n",
      "total test PNEUMONIA images: 119\n",
      "\n",
      "Found 2400 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n",
      "\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "base_train_dir = 'xray1200/train'\n",
    "base_validation_dir = 'xray1200/test/'\n",
    "base_test_dir = 'xray1200/val'\n",
    "\n",
    "train_normal_dir = 'xray1200/train/NORMAL'\n",
    "train_pneumonia_dir = 'xray1200/train/PNEUMONIA'\n",
    "\n",
    "validation_normal_dir = 'xray1200/test/NORMAL'\n",
    "validation_pneumonia_dir = 'xray1200/test/PNEUMONIA'\n",
    "\n",
    "test_normal_dir = 'xray1200/val/NORMAL'\n",
    "test_pneumonia_dir = 'xray1200/val/PNEUMONIA'\n",
    "\n",
    "print('total traing NORMAL images:', len(os.listdir(train_normal_dir)))\n",
    "print('total traing PNEUMONIA images:', len(os.listdir(train_pneumonia_dir)))\n",
    "print()\n",
    "print('total validation NORMAL images:', len(os.listdir(validation_normal_dir)))\n",
    "print('total validation PNEUMONIA images:', len(os.listdir(validation_pneumonia_dir)))\n",
    "print()\n",
    "print('total test NORMAL images:', len(os.listdir(test_normal_dir)))\n",
    "print('total test PNEUMONIA images:', len(os.listdir(test_pneumonia_dir)))\n",
    "print()\n",
    "\n",
    "# преобразование значений пикселей к 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=20,\n",
    "                                  zoom_range=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        base_train_dir, \n",
    "        target_size=(150, 150), #размер изображения\n",
    "        batch_size=20, #размер пакета\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        base_validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "print()\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 391ms/step - loss: 0.6559 - acc: 0.7304 - val_loss: 0.4165 - val_acc: 0.8083\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 42s 346ms/step - loss: 0.3649 - acc: 0.8446 - val_loss: 0.3705 - val_acc: 0.8467\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.3084 - acc: 0.8762 - val_loss: 0.3417 - val_acc: 0.8617\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 42s 351ms/step - loss: 0.2813 - acc: 0.8854 - val_loss: 0.3557 - val_acc: 0.8617\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.2503 - acc: 0.8979 - val_loss: 0.3507 - val_acc: 0.8600\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.2396 - acc: 0.9054 - val_loss: 0.3620 - val_acc: 0.8633\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.2217 - acc: 0.9150 - val_loss: 0.5635 - val_acc: 0.7817\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 42s 351ms/step - loss: 0.2444 - acc: 0.9037 - val_loss: 0.4419 - val_acc: 0.8450\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 41s 343ms/step - loss: 0.2339 - acc: 0.9096 - val_loss: 0.3837 - val_acc: 0.8717\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 42s 349ms/step - loss: 0.2491 - acc: 0.9062 - val_loss: 0.3461 - val_acc: 0.8717\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.2157 - acc: 0.9108 - val_loss: 0.3828 - val_acc: 0.8683\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 45s 378ms/step - loss: 0.2142 - acc: 0.9208 - val_loss: 0.3670 - val_acc: 0.8667\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 45s 376ms/step - loss: 0.2119 - acc: 0.9162 - val_loss: 0.4862 - val_acc: 0.8233\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 370ms/step - loss: 0.1984 - acc: 0.9283 - val_loss: 0.4878 - val_acc: 0.8400\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 44s 368ms/step - loss: 0.1926 - acc: 0.9317 - val_loss: 0.3942 - val_acc: 0.8867\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 49s 410ms/step - loss: 0.5471 - acc: 0.7092 - val_loss: 0.3500 - val_acc: 0.8567\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 45s 372ms/step - loss: 0.3254 - acc: 0.8658 - val_loss: 0.3790 - val_acc: 0.8433\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 45s 375ms/step - loss: 0.2757 - acc: 0.8900 - val_loss: 0.3989 - val_acc: 0.8383\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 45s 371ms/step - loss: 0.2633 - acc: 0.8954 - val_loss: 0.4935 - val_acc: 0.8183\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 46s 385ms/step - loss: 0.2373 - acc: 0.9075 - val_loss: 0.3096 - val_acc: 0.8850\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 46s 384ms/step - loss: 0.2232 - acc: 0.9175 - val_loss: 0.4120 - val_acc: 0.8567\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 46s 384ms/step - loss: 0.2259 - acc: 0.9125 - val_loss: 0.4048 - val_acc: 0.8533\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 46s 387ms/step - loss: 0.1955 - acc: 0.9275 - val_loss: 0.3058 - val_acc: 0.8967\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 46s 383ms/step - loss: 0.1893 - acc: 0.9279 - val_loss: 0.3258 - val_acc: 0.8833\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 46s 383ms/step - loss: 0.1844 - acc: 0.9300 - val_loss: 0.4766 - val_acc: 0.8367\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 46s 386ms/step - loss: 0.1895 - acc: 0.9304 - val_loss: 0.3362 - val_acc: 0.8833\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 46s 384ms/step - loss: 0.1820 - acc: 0.9387 - val_loss: 0.3155 - val_acc: 0.9033\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 46s 386ms/step - loss: 0.1815 - acc: 0.9342 - val_loss: 0.3519 - val_acc: 0.9017\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 47s 388ms/step - loss: 0.1706 - acc: 0.9346 - val_loss: 0.3391 - val_acc: 0.9033\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 46s 386ms/step - loss: 0.1550 - acc: 0.9412 - val_loss: 0.3504 - val_acc: 0.8983\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 50s 419ms/step - loss: 0.5987 - acc: 0.6333 - val_loss: 0.4524 - val_acc: 0.8233\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 46s 381ms/step - loss: 0.3559 - acc: 0.8562 - val_loss: 0.3393 - val_acc: 0.8750\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 46s 385ms/step - loss: 0.2696 - acc: 0.8983 - val_loss: 0.2973 - val_acc: 0.8917\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 46s 385ms/step - loss: 0.2516 - acc: 0.9037 - val_loss: 0.3196 - val_acc: 0.8933\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 357ms/step - loss: 0.2422 - acc: 0.9046 - val_loss: 0.3561 - val_acc: 0.8650\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 45s 376ms/step - loss: 0.2051 - acc: 0.9237 - val_loss: 0.3362 - val_acc: 0.9000\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 45s 373ms/step - loss: 0.1911 - acc: 0.9317 - val_loss: 0.3367 - val_acc: 0.8967\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 44s 370ms/step - loss: 0.2067 - acc: 0.9287 - val_loss: 0.2860 - val_acc: 0.9000\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.1894 - acc: 0.9333 - val_loss: 0.3974 - val_acc: 0.8850\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.1791 - acc: 0.9350 - val_loss: 0.3159 - val_acc: 0.8933\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1672 - acc: 0.9371 - val_loss: 0.3530 - val_acc: 0.9033\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.1759 - acc: 0.9417 - val_loss: 0.3454 - val_acc: 0.8917\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.1814 - acc: 0.9333 - val_loss: 0.3060 - val_acc: 0.9050\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.1814 - acc: 0.9400 - val_loss: 0.3677 - val_acc: 0.8983\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.1745 - acc: 0.9421 - val_loss: 0.2909 - val_acc: 0.8983\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 394ms/step - loss: 0.6531 - acc: 0.5963 - val_loss: 0.4982 - val_acc: 0.8283\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.4544 - acc: 0.7958 - val_loss: 0.3168 - val_acc: 0.8717\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.3651 - acc: 0.8496 - val_loss: 0.3560 - val_acc: 0.8600\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.3037 - acc: 0.8812 - val_loss: 0.2951 - val_acc: 0.8833\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 355ms/step - loss: 0.2702 - acc: 0.9000 - val_loss: 0.3927 - val_acc: 0.8467\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.2603 - acc: 0.8975 - val_loss: 0.3009 - val_acc: 0.8817\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 41s 339ms/step - loss: 0.2224 - acc: 0.9221 - val_loss: 0.3134 - val_acc: 0.8800\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 41s 342ms/step - loss: 0.2165 - acc: 0.9267 - val_loss: 0.3608 - val_acc: 0.8733\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 41s 338ms/step - loss: 0.2102 - acc: 0.9254 - val_loss: 0.3290 - val_acc: 0.8733\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 41s 340ms/step - loss: 0.1923 - acc: 0.9329 - val_loss: 0.3816 - val_acc: 0.8817\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 41s 339ms/step - loss: 0.1940 - acc: 0.9387 - val_loss: 0.3273 - val_acc: 0.8900\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 41s 340ms/step - loss: 0.2006 - acc: 0.9300 - val_loss: 0.3325 - val_acc: 0.8950\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.1728 - acc: 0.9421 - val_loss: 0.2873 - val_acc: 0.8883\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1866 - acc: 0.9375 - val_loss: 0.3685 - val_acc: 0.8733\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.1902 - acc: 0.9337 - val_loss: 0.3062 - val_acc: 0.8917\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 44s 370ms/step - loss: 0.5499 - acc: 0.7408 - val_loss: 0.4040 - val_acc: 0.8133\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.3138 - acc: 0.8725 - val_loss: 0.3371 - val_acc: 0.8617\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 43s 357ms/step - loss: 0.2980 - acc: 0.8758 - val_loss: 0.4037 - val_acc: 0.8200\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2363 - acc: 0.9112 - val_loss: 0.4705 - val_acc: 0.7967\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2602 - acc: 0.8929 - val_loss: 0.4293 - val_acc: 0.8050\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2507 - acc: 0.9033 - val_loss: 0.4121 - val_acc: 0.8350\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2240 - acc: 0.9117 - val_loss: 0.5304 - val_acc: 0.7833\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.2208 - acc: 0.9150 - val_loss: 0.3368 - val_acc: 0.8933\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.2123 - acc: 0.9179 - val_loss: 0.4118 - val_acc: 0.8417\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.2179 - acc: 0.9154 - val_loss: 0.3560 - val_acc: 0.8750\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2017 - acc: 0.9183 - val_loss: 0.3052 - val_acc: 0.8933\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.2013 - acc: 0.9196 - val_loss: 0.3660 - val_acc: 0.8817\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1920 - acc: 0.9258 - val_loss: 0.4441 - val_acc: 0.8617\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.2035 - acc: 0.9167 - val_loss: 0.4120 - val_acc: 0.8533\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.1855 - acc: 0.9350 - val_loss: 0.4734 - val_acc: 0.8283\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 395ms/step - loss: 0.5458 - acc: 0.6896 - val_loss: 0.3329 - val_acc: 0.8717\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.3069 - acc: 0.8712 - val_loss: 0.3375 - val_acc: 0.8600\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.2720 - acc: 0.8942 - val_loss: 0.3274 - val_acc: 0.8850\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2414 - acc: 0.9050 - val_loss: 0.3174 - val_acc: 0.8917\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2355 - acc: 0.9125 - val_loss: 0.3604 - val_acc: 0.8750\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.2200 - acc: 0.9225 - val_loss: 0.5300 - val_acc: 0.8150\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.2021 - acc: 0.9196 - val_loss: 0.3735 - val_acc: 0.8867\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.1929 - acc: 0.9337 - val_loss: 0.3463 - val_acc: 0.8767\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.2117 - acc: 0.9212 - val_loss: 0.4901 - val_acc: 0.8250\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2046 - acc: 0.9262 - val_loss: 0.5692 - val_acc: 0.8117\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.1839 - acc: 0.9329 - val_loss: 0.3106 - val_acc: 0.9000\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.1711 - acc: 0.9412 - val_loss: 0.5075 - val_acc: 0.8433\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1801 - acc: 0.9383 - val_loss: 0.4106 - val_acc: 0.9000\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.1793 - acc: 0.9375 - val_loss: 0.4413 - val_acc: 0.8933\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1674 - acc: 0.9342 - val_loss: 0.4056 - val_acc: 0.8950\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 390ms/step - loss: 0.5335 - acc: 0.7183 - val_loss: 0.3410 - val_acc: 0.8550\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.3358 - acc: 0.8675 - val_loss: 0.3002 - val_acc: 0.8967\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.2847 - acc: 0.8954 - val_loss: 0.4040 - val_acc: 0.8600\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.2421 - acc: 0.9137 - val_loss: 0.4391 - val_acc: 0.8750\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2158 - acc: 0.9187 - val_loss: 0.3556 - val_acc: 0.8917\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.2109 - acc: 0.9225 - val_loss: 0.3710 - val_acc: 0.8983\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1768 - acc: 0.9400 - val_loss: 0.3510 - val_acc: 0.8867\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1831 - acc: 0.9367 - val_loss: 0.3573 - val_acc: 0.8867\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1919 - acc: 0.9283 - val_loss: 0.3750 - val_acc: 0.8983\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1878 - acc: 0.9354 - val_loss: 0.4291 - val_acc: 0.8467\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1633 - acc: 0.9412 - val_loss: 0.4002 - val_acc: 0.8750\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1804 - acc: 0.9375 - val_loss: 0.3692 - val_acc: 0.9017\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1513 - acc: 0.9479 - val_loss: 0.3741 - val_acc: 0.8900\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.1582 - acc: 0.9471 - val_loss: 0.3185 - val_acc: 0.9150\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 42s 351ms/step - loss: 0.1762 - acc: 0.9408 - val_loss: 0.4090 - val_acc: 0.8933\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 393ms/step - loss: 0.6189 - acc: 0.6508 - val_loss: 0.5770 - val_acc: 0.7683\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.4304 - acc: 0.8088 - val_loss: 0.5002 - val_acc: 0.8417\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 42s 353ms/step - loss: 0.3308 - acc: 0.8696 - val_loss: 0.4069 - val_acc: 0.8683\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2790 - acc: 0.8929 - val_loss: 0.3293 - val_acc: 0.8833\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2405 - acc: 0.9137 - val_loss: 0.4555 - val_acc: 0.8667\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 42s 353ms/step - loss: 0.2480 - acc: 0.9062 - val_loss: 0.3424 - val_acc: 0.8817\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 42s 350ms/step - loss: 0.2206 - acc: 0.9237 - val_loss: 0.3113 - val_acc: 0.8917\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.1973 - acc: 0.9337 - val_loss: 0.4242 - val_acc: 0.8867\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2082 - acc: 0.9304 - val_loss: 0.4217 - val_acc: 0.8983\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1852 - acc: 0.9421 - val_loss: 0.3006 - val_acc: 0.9050\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 357ms/step - loss: 0.1974 - acc: 0.9246 - val_loss: 0.3953 - val_acc: 0.8767\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 42s 347ms/step - loss: 0.1970 - acc: 0.9392 - val_loss: 0.4217 - val_acc: 0.8950\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 41s 344ms/step - loss: 0.1857 - acc: 0.9329 - val_loss: 0.4108 - val_acc: 0.8900\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 42s 349ms/step - loss: 0.1746 - acc: 0.9379 - val_loss: 0.3109 - val_acc: 0.9133\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 42s 349ms/step - loss: 0.1602 - acc: 0.9442 - val_loss: 0.4039 - val_acc: 0.8983\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 44s 370ms/step - loss: 0.5499 - acc: 0.7408 - val_loss: 0.4040 - val_acc: 0.8133\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.3138 - acc: 0.8725 - val_loss: 0.3371 - val_acc: 0.8617\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 43s 357ms/step - loss: 0.2980 - acc: 0.8758 - val_loss: 0.4037 - val_acc: 0.8200\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2363 - acc: 0.9112 - val_loss: 0.4705 - val_acc: 0.7967\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2602 - acc: 0.8929 - val_loss: 0.4293 - val_acc: 0.8050\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2507 - acc: 0.9033 - val_loss: 0.4121 - val_acc: 0.8350\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2240 - acc: 0.9117 - val_loss: 0.5304 - val_acc: 0.7833\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.2208 - acc: 0.9150 - val_loss: 0.3368 - val_acc: 0.8933\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.2123 - acc: 0.9179 - val_loss: 0.4118 - val_acc: 0.8417\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.2179 - acc: 0.9154 - val_loss: 0.3560 - val_acc: 0.8750\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2017 - acc: 0.9183 - val_loss: 0.3052 - val_acc: 0.8933\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.2013 - acc: 0.9196 - val_loss: 0.3660 - val_acc: 0.8817\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1920 - acc: 0.9258 - val_loss: 0.4441 - val_acc: 0.8617\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.2035 - acc: 0.9167 - val_loss: 0.4120 - val_acc: 0.8533\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.1855 - acc: 0.9350 - val_loss: 0.4734 - val_acc: 0.8283\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 395ms/step - loss: 0.5458 - acc: 0.6896 - val_loss: 0.3329 - val_acc: 0.8717\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.3069 - acc: 0.8712 - val_loss: 0.3375 - val_acc: 0.8600\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.2720 - acc: 0.8942 - val_loss: 0.3274 - val_acc: 0.8850\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2414 - acc: 0.9050 - val_loss: 0.3174 - val_acc: 0.8917\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.2355 - acc: 0.9125 - val_loss: 0.3604 - val_acc: 0.8750\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.2200 - acc: 0.9225 - val_loss: 0.5300 - val_acc: 0.8150\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.2021 - acc: 0.9196 - val_loss: 0.3735 - val_acc: 0.8867\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.1929 - acc: 0.9337 - val_loss: 0.3463 - val_acc: 0.8767\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.2117 - acc: 0.9212 - val_loss: 0.4901 - val_acc: 0.8250\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2046 - acc: 0.9262 - val_loss: 0.5692 - val_acc: 0.8117\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.1839 - acc: 0.9329 - val_loss: 0.3106 - val_acc: 0.9000\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.1711 - acc: 0.9412 - val_loss: 0.5075 - val_acc: 0.8433\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1801 - acc: 0.9383 - val_loss: 0.4106 - val_acc: 0.9000\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.1793 - acc: 0.9375 - val_loss: 0.4413 - val_acc: 0.8933\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1674 - acc: 0.9342 - val_loss: 0.4056 - val_acc: 0.8950\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 390ms/step - loss: 0.5335 - acc: 0.7183 - val_loss: 0.3410 - val_acc: 0.8550\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.3358 - acc: 0.8675 - val_loss: 0.3002 - val_acc: 0.8967\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.2847 - acc: 0.8954 - val_loss: 0.4040 - val_acc: 0.8600\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 43s 360ms/step - loss: 0.2421 - acc: 0.9137 - val_loss: 0.4391 - val_acc: 0.8750\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2158 - acc: 0.9187 - val_loss: 0.3556 - val_acc: 0.8917\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.2109 - acc: 0.9225 - val_loss: 0.3710 - val_acc: 0.8983\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1768 - acc: 0.9400 - val_loss: 0.3510 - val_acc: 0.8867\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1831 - acc: 0.9367 - val_loss: 0.3573 - val_acc: 0.8867\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1919 - acc: 0.9283 - val_loss: 0.3750 - val_acc: 0.8983\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 43s 361ms/step - loss: 0.1878 - acc: 0.9354 - val_loss: 0.4291 - val_acc: 0.8467\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.1633 - acc: 0.9412 - val_loss: 0.4002 - val_acc: 0.8750\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1804 - acc: 0.9375 - val_loss: 0.3692 - val_acc: 0.9017\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 43s 358ms/step - loss: 0.1513 - acc: 0.9479 - val_loss: 0.3741 - val_acc: 0.8900\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.1582 - acc: 0.9471 - val_loss: 0.3185 - val_acc: 0.9150\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 42s 351ms/step - loss: 0.1762 - acc: 0.9408 - val_loss: 0.4090 - val_acc: 0.8933\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 393ms/step - loss: 0.6189 - acc: 0.6508 - val_loss: 0.5770 - val_acc: 0.7683\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.4304 - acc: 0.8088 - val_loss: 0.5002 - val_acc: 0.8417\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 42s 353ms/step - loss: 0.3308 - acc: 0.8696 - val_loss: 0.4069 - val_acc: 0.8683\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2790 - acc: 0.8929 - val_loss: 0.3293 - val_acc: 0.8833\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2405 - acc: 0.9137 - val_loss: 0.4555 - val_acc: 0.8667\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 42s 353ms/step - loss: 0.2480 - acc: 0.9062 - val_loss: 0.3424 - val_acc: 0.8817\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 42s 350ms/step - loss: 0.2206 - acc: 0.9237 - val_loss: 0.3113 - val_acc: 0.8917\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.1973 - acc: 0.9337 - val_loss: 0.4242 - val_acc: 0.8867\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.2082 - acc: 0.9304 - val_loss: 0.4217 - val_acc: 0.8983\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1852 - acc: 0.9421 - val_loss: 0.3006 - val_acc: 0.9050\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 43s 357ms/step - loss: 0.1974 - acc: 0.9246 - val_loss: 0.3953 - val_acc: 0.8767\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 42s 347ms/step - loss: 0.1970 - acc: 0.9392 - val_loss: 0.4217 - val_acc: 0.8950\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 41s 344ms/step - loss: 0.1857 - acc: 0.9329 - val_loss: 0.4108 - val_acc: 0.8900\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 42s 349ms/step - loss: 0.1746 - acc: 0.9379 - val_loss: 0.3109 - val_acc: 0.9133\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 42s 349ms/step - loss: 0.1602 - acc: 0.9442 - val_loss: 0.4039 - val_acc: 0.8983\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 47s 390ms/step - loss: 0.6318 - acc: 0.7442 - val_loss: 0.3511 - val_acc: 0.8550\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.3062 - acc: 0.8758 - val_loss: 0.3198 - val_acc: 0.8750\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 41s 345ms/step - loss: 0.2582 - acc: 0.8987 - val_loss: 0.4762 - val_acc: 0.8000\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.2614 - acc: 0.8975 - val_loss: 0.3188 - val_acc: 0.8783\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 41s 342ms/step - loss: 0.2477 - acc: 0.9071 - val_loss: 0.3569 - val_acc: 0.8767\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 41s 345ms/step - loss: 0.2339 - acc: 0.9154 - val_loss: 0.3571 - val_acc: 0.8733\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 42s 350ms/step - loss: 0.2321 - acc: 0.9117 - val_loss: 0.4175 - val_acc: 0.8517\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 42s 346ms/step - loss: 0.2033 - acc: 0.9233 - val_loss: 0.4040 - val_acc: 0.8567\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 41s 343ms/step - loss: 0.2193 - acc: 0.9146 - val_loss: 0.4478 - val_acc: 0.8400\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 41s 341ms/step - loss: 0.2226 - acc: 0.9092 - val_loss: 0.3121 - val_acc: 0.8967\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 41s 345ms/step - loss: 0.2128 - acc: 0.9175 - val_loss: 0.3545 - val_acc: 0.8833\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 42s 347ms/step - loss: 0.2007 - acc: 0.9275 - val_loss: 0.4375 - val_acc: 0.8650\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 42s 347ms/step - loss: 0.2070 - acc: 0.9221 - val_loss: 0.3678 - val_acc: 0.8833\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 41s 343ms/step - loss: 0.1909 - acc: 0.9287 - val_loss: 0.4686 - val_acc: 0.8583\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 41s 340ms/step - loss: 0.1883 - acc: 0.9275 - val_loss: 0.3753 - val_acc: 0.8933\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - 48s 399ms/step - loss: 0.5589 - acc: 0.6904 - val_loss: 0.4553 - val_acc: 0.8217\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 45s 376ms/step - loss: 0.2968 - acc: 0.8796 - val_loss: 0.4392 - val_acc: 0.8567\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 44s 363ms/step - loss: 0.2702 - acc: 0.8946 - val_loss: 0.4431 - val_acc: 0.8683\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 42s 346ms/step - loss: 0.2328 - acc: 0.9058 - val_loss: 0.4144 - val_acc: 0.8850\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 42s 346ms/step - loss: 0.2442 - acc: 0.8979 - val_loss: 0.3639 - val_acc: 0.8850\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 42s 350ms/step - loss: 0.2332 - acc: 0.9117 - val_loss: 0.4774 - val_acc: 0.8550\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 368ms/step - loss: 0.2195 - acc: 0.9183 - val_loss: 0.4034 - val_acc: 0.8883\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 42s 350ms/step - loss: 0.2193 - acc: 0.9225 - val_loss: 0.5920 - val_acc: 0.8217\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 42s 352ms/step - loss: 0.2045 - acc: 0.9242 - val_loss: 0.5728 - val_acc: 0.8167\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.1784 - acc: 0.9367 - val_loss: 0.4213 - val_acc: 0.8883\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 42s 353ms/step - loss: 0.1862 - acc: 0.9371 - val_loss: 0.4077 - val_acc: 0.8933\n",
      "Epoch 12/15\n",
      "106/120 [=========================>....] - ETA: 4s - loss: 0.1859 - acc: 0.9330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-245d84c960b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                 callbacks=[tensorboard])\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/i5-6400/anaconda3/envs/mmmj/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [64, 128, 256]\n",
    "conv_layers = [1, 2, 3, 4]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, \n",
    "                                                         layer_size, \n",
    "                                                         dense_layer, \n",
    "                                                         int(time.time()))\n",
    "\n",
    "            model = models.Sequential()\n",
    "            \n",
    "            model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                                    input_shape=(150, 150, 3)))\n",
    "            model.add(layers.MaxPooling2D((2, 2)))\n",
    "            \n",
    "            for layer in range(conv_layer-1):\n",
    "                model.add(layers.Conv2D(layer_size, (3, 3), activation='relu'))\n",
    "                model.add(layers.MaxPooling2D((2, 2)))\n",
    "               \n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dropout(0.5))\n",
    "            \n",
    "            for layer in range(dense_layer):\n",
    "                model.add(layers.Dense(layer_size, activation='relu'))\n",
    "                \n",
    "            model.add(layers.Dense(1, activation='sigmoid'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            \n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['acc'])\n",
    "            \n",
    "            model.fit_generator(\n",
    "                                train_generator,\n",
    "                                steps_per_epoch=120,\n",
    "                                epochs=15,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=30,\n",
    "                                callbacks=[tensorboard])\n",
    "                     \n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xray_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 150  \n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # черно-белое  изображдение\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # размер изображения\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "model = tf.keras.models.load_model(\"xray_2.h5\")\n",
    "\n",
    "count_normal = 0\n",
    "count_pneumo = 0\n",
    "\n",
    "for img in os.listdir(test_normal_dir):\n",
    "    prep_img = image.load_img(test_normal_dir+'/'+img, target_size=(150, 150))\n",
    "    x = image.img_to_array(prep_img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    prediction = model.predict(x)\n",
    "    if prediction == 0:\n",
    "        count_normal +=1\n",
    "\n",
    "print(str(count_normal) + ' from ' + str(len(os.listdir(test_normal_dir))))\n",
    "\n",
    "    \n",
    "for img in os.listdir(test_pneumonia_dir):\n",
    "    prep_img = image.load_img(test_pneumonia_dir+'/'+img, target_size=(150, 150))\n",
    "    x = image.img_to_array(prep_img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    prediction = model.predict(x)\n",
    "    if prediction == 1:\n",
    "        count_pneumo +=1\n",
    "    \n",
    "print(str(count_pneumo) + ' from ' + str(len(os.listdir(test_pneumonia_dir))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
